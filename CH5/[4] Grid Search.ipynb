{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "\n",
    "A for loop is useful for automating the search of a single hyperparameter. However, we usually want to find more than one hyperparameter. How can we do so?\n",
    "\n",
    "## 1. Nested For Loop"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Finding the best values for learn_rate and max_depth for GradientBoostingClassifier\n",
    "\n",
    "# Function\n",
    "def gbm_grid_search(learn_rate, max_depth):\n",
    "    # model using the given hyperparameters\n",
    "    model = GradientBoostingClassifier(\n",
    "            learning_rate=learn_rate,\n",
    "            max_depth=max_depth)\n",
    "            \n",
    "    # return accuracy\n",
    "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
    "    return([learn_rate, max_depth, accuracy_score(y_test, predictins)])\n",
    "\n",
    "# Nested for loop\n",
    "results_list = []\n",
    "\n",
    "for learn_rate in learn_rate_list:\n",
    "    for max_depth in max_depth_list:\n",
    "        results_list.append(gbm_grid_search(learn_rate, max_depth))\n",
    "\n",
    "# Analyse data frame\n",
    "results_df = pd.DataFrame(results_list, columns=[\"learning_rate\", \"max_depth\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the more values and hyperparameters we test, the search time grows exponentially. Is there a way to run this search more efficiently?\n",
    "\n",
    "## 2. Grid Search\n",
    "- create a grid, rows are one hyperparameter, columns are another\n",
    "- run the function for each cell\n",
    "- can run in parallel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.modelselection import GridSearchCV\n",
    "\n",
    "# Create the grid, must be a dictionary\n",
    "param_grid = {\"max_depth\": [2, 4, 6, 8], \"min_samples_leaf\":[1, 2, 4, 6]}\n",
    "\n",
    "# Get base classifier\n",
    "rf_class = RandomForestClassifier(criterion=\"entropy\", max_features=\"auto\")\n",
    "\n",
    "# Instantiate grid search\n",
    "grid_rf_class = GridSearchCV(\n",
    "    estimator = rf_class, # model type\n",
    "    param_grid = parameter_grid, # hyperparameters and values to test\n",
    "    scoring = \"accuracy\", # evaluation, can select from sklearn.metrics\n",
    "    n_jobs = 4, # number of cores running function in parallel\n",
    "    cv = 10, # cross validation folds\n",
    "    refit = True # at the end, retrains the model with the best hyperparameters, allows grid search to be used as it\n",
    "    return_train_score = True # returns the training score\n",
    ")\n",
    "\n",
    "grid_rf_class.fit(X_train, y_train)\n",
    "grid_rf_class.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that grid search is still not perfect as it is still computationally expensive. It is a type of uninformed search as one search does not inform the ones that come after it. Hence, it is still rather inefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Output\n",
    "\n",
    "1. Result logs\n",
    "    - cv_results_\n",
    "\n",
    "2. Best results\n",
    "    - best_index_, best_params_, best_score_, best_estimator_\n",
    "\n",
    "3. Extra information\n",
    "    - scorer_, n_splits_, refit_time_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
