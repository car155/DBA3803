{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "## Regulatisation\n",
    "\n",
    "Regularisation helps to combat overfitting by reducing the size of regression coefficients. In scikit.learn, C is inversely related to the regularisation coefficient. Hence, a smaller C increases regularisation, restricting regression coefficients more."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr_weak_reg = LogisticRegression(C=100)\n",
    "lr_strong_reg = LogisticRegression(C=0.1)\n",
    "\n",
    "lr_weak_reg.fit(X_train, y_train)\n",
    "lr_strong_reg.fit(X_train, y_train)\n",
    "\n",
    "lr_weak_reg.score(X_test, y_test)\n",
    "lr_strong_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression automatically uses Ridge to regularise the model. We can change this to lasso using **penalty=\"L1\"**. We can also use"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Specify L1 regularization\n",
    "lr = LogisticRegression(penalty=\"l1\")\n",
    "\n",
    "# Instantiate the GridSearchCV object and run the search\n",
    "searcher = GridSearchCV(lr, {'C':[0.001, 0.01, 0.1, 1, 10]})\n",
    "searcher.fit(X_train, y_train)\n",
    "\n",
    "# Report the best parameters\n",
    "print(\"Best CV params\", searcher.best_params_)\n",
    "\n",
    "# Find the number of nonzero coefficients (selected features)\n",
    "best_lr = searcher.best_estimator_\n",
    "coefs = best_lr.coef_\n",
    "print(\"Total number of features:\", coefs.size)\n",
    "print(\"Number of selected features:\", np.count_nonzero(coefs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilities\n",
    "\n",
    "In scikit.learn, the LogisticRegression object can predict probabilities using the **predict_proba** function.\n",
    "\n",
    "The prediction classification of the model can be foung using **decision_function**. However, this raw model output needs to be squashed. We can use the **sigmoid** function to do so."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Set the regularization strength\n",
    "model = LogisticRegression(C=0.1)\n",
    "\n",
    "# Fit and plot\n",
    "model.fit(X,y)\n",
    "plot_classifier(X,y,model,proba=True)\n",
    "\n",
    "# Predict probabilities on training points\n",
    "prob = model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class Classification\n",
    "\n",
    "### One-vs-rest\n",
    "\n",
    "We can do this manually by training the data on 3 different classifications, one for each category. Then, we choose the one with the highest confidence."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr0.fit(X, y==0)\n",
    "lr1.fit(X, y==1)\n",
    "lr2.fit(X, y==2)\n",
    "\n",
    "lr0.decision_function(X)[0]\n",
    "lr1.decision_function(X)[1]\n",
    "lr2.decision_function(X)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this one-vs-rest approach can be done automatically on scikit learn."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr.fit(X, y)\n",
    "lr.predict(X)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial or Softmax\n",
    "\n",
    "This method tries to change the loss function to optimise for multiple categorisations. This might be more accurate since it optimises the loss directly. However, it is more complicated."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr_mn = LogisticRegression(multi_class=\"multinomial\",\n",
    "                          solver=\"lbfgs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
